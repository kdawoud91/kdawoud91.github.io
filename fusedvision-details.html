<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>FusedVision — Practical Anomaly Detection (CVPRW 2025)</title>
  <meta name="description" content="FusedVision: a knowledge-infusing approach for practical anomaly detection in real-world videos (CVPR Workshops 2025)." />
  <meta name="theme-color" content="#7c3aed" />
  <style>
    :root{--bg:#0b1220;--card:#0f172a;--muted:#94a3b8;--text:#e2e8f0;--brand:#7c3aed;--ring:rgba(124,58,237,.35)}
    :root.light{--bg:#ffffff;--card:#f8fafc;--muted:#475569;--text:#0f172a}
    *{box-sizing:border-box}
    body{margin:0;font-family:ui-sans-serif,system-ui,-apple-system,Segoe UI,Roboto,Inter,Arial;line-height:1.6;background:var(--bg);color:var(--text)}
    a{color:inherit;text-decoration:none}
    .container{max-width:1000px;margin:0 auto;padding:24px}
    .muted{color:var(--muted)}
    .card{background:var(--card);border:1px solid color-mix(in oklab, var(--muted) 25%, transparent);border-radius:16px;padding:18px}
    .divider{height:1px;background:color-mix(in oklab, var(--muted) 22%, transparent);margin:12px 0}
    .stack{display:flex;flex-wrap:wrap;gap:.5rem}
    .tag{display:inline-block;font-size:.8rem;padding:.2rem .5rem;border-radius:999px;border:1px solid color-mix(in oklab, var(--brand) 45%, transparent)}
    h1{font-size:clamp(1.5rem,3vw,2.2rem);margin:.2rem 0}
    h2{font-size:1.2rem;margin:1.4rem 0 .6rem}
    .back{display:inline-flex;gap:.5rem;align-items:center;padding:.5rem .75rem;border:1px solid color-mix(in oklab, var(--brand) 40%, transparent);border-radius:10px;text-decoration:none}
    .tabs{display:flex;gap:.5rem;flex-wrap:wrap}
    .tab{padding:.5rem .9rem;border:1px solid color-mix(in oklab, var(--brand) 35%, transparent);border-radius:999px;cursor:pointer}
    .tab[aria-selected="true"]{background:var(--brand);color:#fff;border-color:transparent}
    .tabpanels > section{display:none}
    .tabpanels > section[aria-hidden="false"]{display:block}
    .btn{display:inline-flex;align-items:center;gap:.4rem;padding:.6rem .85rem;border-radius:12px;border:1px solid color-mix(in oklab, var(--brand) 40%, transparent);cursor:pointer}
    .btn.primary{background:var(--brand);color:#fff;border-color:transparent}
    details{border:1px solid color-mix(in oklab, var(--muted) 25%, transparent);border-radius:12px;padding:10px}
    summary{cursor:pointer;font-weight:600}
    .kpi{display:grid;grid-template-columns:repeat(auto-fit,minmax(180px,1fr));gap:12px}
    .kpi .card{display:grid;gap:8px}
    code, .kbd{font-family:ui-monospace,SFMono-Regular,Menlo,Consolas,monospace}
    .copy{margin-left:.5rem}
    video{border-radius:12px;border:1px solid color-mix(in oklab, var(--muted) 20%, transparent)}
  </style>
  <script>
    const applyTheme=()=>{const mql=window.matchMedia('(prefers-color-scheme: light)').matches;const saved=localStorage.getItem('theme');const light=saved?saved==='light':mql;document.documentElement.classList.toggle('light',light)};
    window.addEventListener('DOMContentLoaded',()=>{applyTheme();
      // tabs
      const tabs=document.querySelectorAll('.tab');
      const panels=document.querySelectorAll('.tabpanels > section');
      function show(i){tabs.forEach((t,j)=>t.setAttribute('aria-selected',j===i));panels.forEach((p,j)=>p.setAttribute('aria-hidden',j!==i));}
      tabs.forEach((t,i)=>t.addEventListener('click',()=>show(i)));show(0);
      // copy helper
      document.querySelectorAll('[data-copy]').forEach(btn=>btn.addEventListener('click',()=>{
        const id=btn.getAttribute('data-copy');
        const text=document.getElementById(id).textContent;
        navigator.clipboard.writeText(text).then(()=>{btn.textContent='Copied!';setTimeout(()=>btn.textContent='Copy',1000)});
      }));
    });
  </script>
</head>
<body>
  <main class="container">
    <a href="index.html#publications" class="back">← Back</a>

    <header class="card" style="margin-top:12px">
      <h1>FusedVision: A Knowledge-Infusing Approach for Practical Anomaly Detection in Real-world Videos</h1>
      <p class="muted">CVPR Workshops, 2025 • Khaled Dawoud; Muhammad Zaigham Zaheer; Mustaqeem Khan; Karthik Nandakumar; Abdulmotaleb El Saddik; Muhammad Haris Khan</p>
      <div class="stack" style="margin-top:.5rem"><span class="tag">Anomaly Detection</span><span class="tag">Computer Vision</span><span class="tag">Knowledge Infusion</span><span class="tag">Object-centric</span></div>
      <div class="divider"></div>
      <div class="tabs" role="tablist" aria-label="FusedVision sections">
        <button class="tab" role="tab" aria-selected="true">Overview</button>
        <button class="tab" role="tab">Method</button>
        <button class="tab" role="tab">Results</button>
        <button class="tab" role="tab">Artifacts</button>
      </div>
    </header>

    <div class="tabpanels">
      <!-- Overview -->
      <section aria-hidden="false">
        <article class="card">
          <h2>Abstract (plain-English)</h2>
          <p>Object-centric video anomaly detection isolates objects in each frame and learns what looks normal. <strong>FusedVision</strong> augments this with a branched design that combines an object detector and a normalcy model, then <em>infuses knowledge about expected anomalies</em> to guide fusion and scoring. The goal is practical deployment: higher precision and better robustness under everyday shifts (crowds, lighting, clutter) without sacrificing recall.</p>
          <details><summary>Abstract (from paper)</summary>
            <p>Object-centric approaches have gained attention as effective one-class classification methods for detecting anomalies in videos... Our proposed approach noticeably outperforms existing methods, demonstrating its effectiveness across contexts. <em>Source: CVPRW 2025 paper.</em></p>
          </details>

          <h2>Motivation</h2>
          <p>Deployed video safety detection systems face challenges that controlled lab conditions rarely capture—dynamic backgrounds, shifting illumination, and unpredictable crowd behaviors. Conventional object-centric models rely solely on learned representations of “normal,” making them vulnerable to false alarms or missed anomalies as conditions change. FusedVision mitigates this by infusing explicit knowledge of plausible anomalies into the detection pipeline, yielding more consistent, context-aware, operational performance in real-world settings.</p>

          <h2>Key Contributions</h2>
          <ul>
            <li>Branched architecture coupling an <strong>object detector</strong> with a <strong>normalcy model</strong> for complementary cues.</li>
            <li><strong>Knowledge-infused fusion</strong> and <strong>anomaly scoring</strong> tailored to practical deployments.</li>
            <li><strong>Plug-in design</strong>: integrates with recent methods; validated on ShanghaiTech, Avenue, and UCSD Ped2.</li>
          </ul>

          <div class="divider"></div>
          <h2>Video Demo</h2>
          <video id="demo-video-overview" width="100%" controls poster="assets/fusedvision-thumb.jpg">
            <source src="assets/fusedvision-demo.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
          <p class="muted">Click play to watch FusedVision detecting anomalies under challenging conditions.</p>
        </article>
      </section>

      <!-- Method -->
      <section aria-hidden="true">
        <article class="card">
          <h2>System Architecture</h2>
          <p>FusedVision follows an object-centric pipeline augmented with knowledge infusion:</p>
          <div class="kpi">
            <div class="card">
              <strong>Perception</strong>
              <div class="divider"></div>
              <ul>
                <li>Object detector extracts instance crops and metadata</li>
                <li>Normalcy model learns typical appearance/motion</li>
              </ul>
            </div>
            <div class="card">
              <strong>Knowledge Layer</strong>
              <div class="divider"></div>
              <ul>
                <li>Domain priors about anomaly types</li>
                <li>Adapters inject priors into detector/normalcy features</li>
              </ul>
            </div>
            <div class="card">
              <strong>Fusion & Scoring</strong>
              <div class="divider"></div>
              <ul>
                <li>Branched fusion of detector + normalcy signals</li>
                <li>Calibrated anomaly scoring for frame/object level</li>
              </ul>
            </div>
          </div>
        </article>
      </section>

      <!-- Results -->
      <section aria-hidden="true">
        <article class="card">
          <h2>Qualitative Results</h2>
          <ul>
            <li>Improved anomaly localization and fewer false positives in crowded scenes.</li>
            <li>Robustness to illumination and context shifts via priors.</li>
            <li>Consistent gains when plugged into different baselines.</li>
          </ul>
          <p class="muted">Datasets reported in the paper: ShanghaiTech, Avenue, UCSD Ped2.</p>

          <h2>Limitations &amp; Future Work</h2>
          <ul>
            <li>Quality of priors matters; poor priors may bias scores.</li>
            <li>Future: automatic prior discovery and adaptive calibration.</li>
          </ul>
        </article>
      </section>

      <!-- Artifacts -->
      <section aria-hidden="true">
        <article class="card">
          <h2>Artifacts</h2>
          <ul>
            <li><a href="assets/Dawoud_FusedVision_A_Knowledge-Infusing_Approach_for_Practical_Anomaly_Detection_in_Real-world_CVPRW_2025_paper.pdf" target="_blank" rel="noopener">Paper (PDF)</a></li>
            <li><a href="https://github.com/kdawoud91/FusedVision" target="_blank" rel="noopener">Code (GitHub)</a></li>
            <li><a href="#" onclick="alert('Add your slide deck URL');return false;">Slides</a></li>
          </ul>
          <div class="divider"></div>
          <details>
            <summary>Citation</summary>
            <pre id="cite"><code>Dawoud, K., Zaheer, M. Z., Khan, M., Nandakumar, K., El Saddik, A., &amp; Khan, M. H. (2025). FusedVision: A Knowledge-Infusing Approach for Practical Anomaly Detection in Real-world Videos. In CVPR Workshops.</code></pre>
            <button class="btn copy" data-copy="cite">Copy</button>
          </details>
        </article>
      </section>
    </div>
  </main>
</body>
</html>
