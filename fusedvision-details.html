<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>FusedVision — Practical Anomaly Detection (CVPRW 2025)</title>
  <meta name="description" content="FusedVision: a knowledge‑infusing approach for practical anomaly detection in real‑world videos (CVPR Workshops 2025)." />
  <meta name="theme-color" content="#7c3aed" />
  <style>
    :root{--bg:#0b1220;--card:#0f172a;--muted:#94a3b8;--text:#e2e8f0;--brand:#7c3aed;--ring:rgba(124,58,237,.35)}
    :root.light{--bg:#ffffff;--card:#f8fafc;--muted:#475569;--text:#0f172a}
    *{box-sizing:border-box}
    body{margin:0;font-family:ui-sans-serif,system-ui,-apple-system,Segoe UI,Roboto,Inter,Arial;line-height:1.6;background:var(--bg);color:var(--text)}
    a{color:inherit;text-decoration:none}
    .container{max-width:1000px;margin:0 auto;padding:24px}
    .muted{color:var(--muted)}
    .card{background:var(--card);border:1px solid color-mix(in oklab, var(--muted) 25%, transparent);border-radius:16px;padding:18px}
    .divider{height:1px;background:color-mix(in oklab, var(--muted) 22%, transparent);margin:12px 0}
    .stack{display:flex;flex-wrap:wrap;gap:.5rem}
    .tag{display:inline-block;font-size:.8rem;padding:.2rem .5rem;border-radius:999px;border:1px solid color-mix(in oklab, var(--brand) 45%, transparent)}
    h1{font-size:clamp(1.5rem,3vw,2.2rem);margin:.2rem 0}
    h2{font-size:1.2rem;margin:1.4rem 0 .6rem}
    .back{display:inline-flex;gap:.5rem;align-items:center;padding:.5rem .75rem;border:1px solid color-mix(in oklab, var(--brand) 40%, transparent);border-radius:10px;text-decoration:none}
    .tabs{display:flex;gap:.5rem;flex-wrap:wrap}
    .tab{padding:.5rem .9rem;border:1px solid color-mix(in oklab, var(--brand) 35%, transparent);border-radius:999px;cursor:pointer}
    .tab[aria-selected="true"]{background:var(--brand);color:#fff;border-color:transparent}
    .tabpanels > section{display:none}
    .tabpanels > section[aria-hidden="false"]{display:block}
    /* Demo */
    .demo-grid{display:grid;grid-template-columns:1fr 1fr;gap:16px}
    .state{display:grid;gap:8px}
    .state .row{display:flex;align-items:center;justify-content:space-between;background:rgba(255,255,255,.03);border:1px solid color-mix(in oklab, var(--muted) 20%, transparent);border-radius:12px;padding:10px}
    .led{width:14px;height:14px;border-radius:50%;box-shadow:0 0 16px 2px rgba(0,0,0,.25)}
    .actions{display:flex;flex-wrap:wrap;gap:.5rem}
    .btn{display:inline-flex;align-items:center;gap:.4rem;padding:.6rem .85rem;border-radius:12px;border:1px solid color-mix(in oklab, var(--brand) 40%, transparent);cursor:pointer}
    .btn.primary{background:var(--brand);color:#fff;border-color:transparent}
    details{border:1px solid color-mix(in oklab, var(--muted) 25%, transparent);border-radius:12px;padding:10px}
    summary{cursor:pointer;font-weight:600}
    .kpi{display:grid;grid-template-columns:repeat(auto-fit,minmax(180px,1fr));gap:12px}
    .kpi .card{display:grid;gap:8px}
    code, .kbd{font-family:ui-monospace,SFMono-Regular,Menlo,Consolas,monospace}
    .copy{margin-left:.5rem}
    video{border-radius:12px;border:1px solid color-mix(in oklab, var(--muted) 20%, transparent)}
  </style>
  <script>
    const applyTheme=()=>{const mql=window.matchMedia('(prefers-color-scheme: light)').matches;const saved=localStorage.getItem('theme');const light=saved?saved==='light':mql;document.documentElement.classList.toggle('light',light)};
    window.addEventListener('DOMContentLoaded',()=>{applyTheme();
      // tabs
      const tabs=document.querySelectorAll('.tab');
      const panels=document.querySelectorAll('.tabpanels > section');
      function show(i){tabs.forEach((t,j)=>t.setAttribute('aria-selected',j===i));panels.forEach((p,j)=>p.setAttribute('aria-hidden',j!==i));}
      tabs.forEach((t,i)=>t.addEventListener('click',()=>show(i)));show(0);
      // copy helper
      document.querySelectorAll('[data-copy]').forEach(btn=>btn.addEventListener('click',()=>{
        const id=btn.getAttribute('data-copy');
        const text=document.getElementById(id).textContent;
        navigator.clipboard.writeText(text).then(()=>{btn.textContent='Copied!';setTimeout(()=>btn.textContent='Copy',1000)});
      }));
    });
  </script>
</head>
<body>
  <main class="container">
    <a href="index.html#publications" class="back">← Back</a>

    <header class="card" style="margin-top:12px">
      <h1>FusedVision: A Knowledge‑Infusing Approach for Practical Anomaly Detection in Real‑world Videos</h1>
      <p class="muted">CVPR Workshops, 2025 • Khaled Dawoud; Muhammad Zaigham Zaheer; Mustaqeem Khan; Karthik Nandakumar; Abdulmotaleb El Saddik; Muhammad Haris Khan</p>
      <div class="stack" style="margin-top:.5rem"><span class="tag">Anomaly Detection</span><span class="tag">Computer Vision</span><span class="tag">Knowledge Infusion</span><span class="tag">Object‑centric</span></div>
      <div class="divider"></div>
      <div class="tabs" role="tablist" aria-label="FusedVision sections">
        <button class="tab" role="tab" aria-selected="true">Overview</button>
        <button class="tab" role="tab">Method</button>
        <button class="tab" role="tab">Demo</button>
        <button class="tab" role="tab">Results</button>
        <button class="tab" role="tab">Artifacts</button>
      </div>
    </header>

    <div class="tabpanels">
      <!-- Overview -->
      <section aria-hidden="false">
        <article class="card">
          <h2>Abstract (plain‑English)</h2>
          <p>Object‑centric video anomaly detection isolates objects in each frame and learns what looks normal. <strong>FusedVision</strong> augments this with a branched design that combines an object detector and a normalcy model, then <em>infuses knowledge about expected anomalies</em> to guide fusion and scoring. The goal is practical deployment: higher precision and better robustness under everyday shifts (crowds, lighting, clutter) without sacrificing recall.</p>
          <details><summary>Abstract (from paper)</summary>
            <p>Object‑centric approaches have gained attention as effective one‑class classification methods for detecting anomalies in videos... Our proposed approach noticeably outperforms existing methods, demonstrating its effectiveness across contexts. <em>Source: CVPRW 2025 paper.</em></p>
          </details>
          <h2>Motivation</h2>
          <p>Deployed video safety detection systems face challenges that controlled lab conditions rarely capture such as dynamic backgrounds, shifting illumination, and unpredictable crowd behaviors. Conventional object-centric models rely solely on learned representations of "normal" patterns, making them vulnerable to false alarms or missed anomalies in changing environments. FusedVision mitigates this by infusing explicit knowledge of plausible anomalies into the detection pipeline, enabling more consistent, context-aware, and operationally relevant performance in real-world settings.</p>
          <h2>Key Contributions</h2>
          <ul>
            <li>Branched architecture coupling an <strong>object detector</strong> with a <strong>normalcy model</strong> for complementary cues.</li>
            <li><strong>Knowledge‑infused fusion</strong> and <strong>anomaly scoring</strong> tailored to practical deployments.</li>
            <li><strong>Plug‑in design</strong>: integrated with multiple recent methods; validated on ShanghaiTech, Avenue, and UCSD Ped2.</li>
          </ul>
          <div class="divider"></div>
          <h2>Video Demo</h2>
          <video id="demo-video-overview" width="100%" controls poster="assets/fusedvision-thumb.jpg">
            <source src="assets/fusedvision-demo.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
          <p class="muted">Click play to watch FusedVision detecting anomalies under challenging conditions.</p>
        </article>
      </section>

      <!-- Method -->
      <section aria-hidden="true">
        <article class="card">
          <h2>System Architecture</h2>
          <p>FusedVision follows an object‑centric pipeline augmented with knowledge infusion:</p>
          <div class="kpi">
            <div class="card"><strong>Perception</strong><div class="divider"></div><ul><li>Object detector extracts instance crops and metadata</li><li>Normalcy model learns typical appearance/motion</li></ul></div>
            <div class="card"><strong>Knowledge Layer</strong><div class="divider"></div><ul><li>Domain priors about anomaly types</li><li> inject priors into object detector</li></ul></div>
            <div class="card"><strong>Fusion & Scoring</strong><div class="divider"></div><ul><li>Branched fusion of detector + normalcy autoencoders(NLMs)</li><li>Calibrated anomaly scoring for frame/object level</li></ul></div>
          </div>
          <h2>Algorithms</h2>
          <details open>
            <summary>High‑level loop</summary>
            <pre id="algo-loop"><code>for frame in video:
  objs = detect_objects(frame)
  z_norm = normalcy_features(objs)
  z_know = knowledge_adapter(objs, priors)
  s = fusion_and_score(z_norm, z_know)
  update_timeline(frame_idx, s)</code></pre>
            <button class="btn copy" data-copy="algo-loop">Copy</button>
          </details>
          <details style="margin-top:.5rem">
            <summary>Knowledge infusion examples</summary>
            <ul>
              <li>Rules/priors on object interactions (e.g., person+bike on sidewalk)</li>
              <li>Context‑aware thresholds conditioned on time/place</li>
              <li>Lightweight adapters mapping priors to feature shifts</li>
            </ul>
          </details>
        </article>
      </section>

      <!-- Demo -->
      <section aria-hidden="true">
        <article class="card">
          <h2>Interactive Demo (simulated)</h2>
          <p>Toggle knowledge infusion to see its qualitative impact on the anomaly score.</p>
          <div class="demo-grid">
            <div class="state">
              <div class="row"><span>Knowledge Layer</span><strong id="kstate">Off</strong></div>
              <div class="row"><span>Anomaly Score</span><strong id="score">0.21</strong></div>
            </div>
            <div class="actions">
              <button class="btn primary" id="toggle">Toggle Knowledge</button>
              <button class="btn" id="reset">Reset</button>
            </div>
          </div>
          <script>
            (function(){
              const k=document.getElementById('kstate');
              const s=document.getElementById('score');
              let on=false; let base=0.21;
              document.getElementById('toggle').onclick=()=>{on=!on;k.textContent=on?'On':'Off';s.textContent=(on? (base*1.35).toFixed(2):(base).toFixed(2));};
              document.getElementById('reset').onclick=()=>{on=false;k.textContent='Off';s.textContent=base.toFixed(2)};
            })();
          </script>
          <p class="muted" style="margin-top:.6rem">Illustrative UI; for real data and plots, see the paper and code.</p>
        </article>
      </section>

      <!-- Results -->
      <section aria-hidden="true">
        <article class="card">
          <h2>Qualitative Results</h2>
          <ul>
            <li>Improved anomaly localization and fewer false positives in crowded scenes.</li>
            <li>Robustness to illumination and context shifts via priors.</li>
            <li>Consistent gains when plugged into different baselines.</li>
          </ul>
          <p class="muted">Datasets reported in the paper: ShanghaiTech, Avenue, UCSD Ped2.</p>
          <h2>Limitations & Future Work</h2>
          <ul>
            <li>Quality of priors matters; poor priors may bias scores.</li>
            <li>Future: automatic prior discovery and adaptive calibration.</li>
          </ul>
        </article>
      </section>

      <!-- Artifacts -->
      <section aria-hidden="true">
        <article class="card">
          <h2>Artifacts</h2>
          <ul>
            <li><a href="assets/Dawoud_FusedVision_A_Knowledge-Infusing_Approach_for_Practical_Anomaly_Detection_in_Real-world_CVPRW_2025_paper.pdf" target="_blank" rel="noopener">Paper (PDF)</a></li>
            <li><a href="https://github.com/kdawoud91/FusedVision" target="_blank" rel="noopener">Code (GitHub)</a></li>
            <li><a href="#" onclick="alert('Add your slide deck URL');return false;">Slides</a></li>
          </ul>
          <div class="divider"></div>
          <details>
            <summary>Citation</summary>
            <pre id="cite"><code>Dawoud, K., Zaheer, M. Z., Khan, M., Nandakumar, K., El Saddik, A., & Khan, M. H. (2025). FusedVision: A Knowledge‑Infusing Approach for Practical Anomaly Detection in Real‑world Videos. In CVPR Workshops.</code></pre>
            <button class="btn copy" data-copy="cite">Copy</button>
          </details>
        </article>
      </section>
    </div>
  </main>
</body>
</html>
